# File generated by CompCert 3.8
# Command line: -stdlib ../../runtime -relf -o sha3.compcert sha3.c -lm
	.option nopic
	.option norelax
	.option norvc
	.section	.rodata
	.balign 1
__stringlit_4:
	.ascii	"Keccak-224 Test Hash\000"
	.type	__stringlit_4, @object
	.size	__stringlit_4, . - __stringlit_4
	.section	.rodata
	.balign 1
__stringlit_6:
	.ascii	"passed\000"
	.type	__stringlit_6, @object
	.size	__stringlit_6, . - __stringlit_6
	.section	.rodata
	.balign 1
__stringlit_1:
	.ascii	"Keccak-512 Test Hash\000"
	.type	__stringlit_1, @object
	.size	__stringlit_1, . - __stringlit_1
	.section	.rodata
	.balign 1
__stringlit_7:
	.ascii	"SHA-3 %d %s\012\000"
	.type	__stringlit_7, @object
	.size	__stringlit_7, . - __stringlit_7
	.section	.rodata
	.balign 1
__stringlit_3:
	.ascii	"Keccak-256 Test Hash\000"
	.type	__stringlit_3, @object
	.size	__stringlit_3, . - __stringlit_3
	.section	.rodata
	.balign 1
__stringlit_2:
	.ascii	"Keccak-384 Test Hash\000"
	.type	__stringlit_2, @object
	.size	__stringlit_2, . - __stringlit_2
	.section	.rodata
	.balign 1
__stringlit_5:
	.ascii	"FAILED\000"
	.type	__stringlit_5, @object
	.size	__stringlit_5, . - __stringlit_5
	.section	.rodata
	.balign 8
	.globl	keccakf_rndc
keccakf_rndc:
	.long	0x1, 0x0
	.long	0x8082, 0x0
	.long	0x808a, 0x80000000
	.long	0x80008000, 0x80000000
	.long	0x808b, 0x0
	.long	0x80000001, 0x0
	.long	0x80008081, 0x80000000
	.long	0x8009, 0x80000000
	.long	0x8a, 0x0
	.long	0x88, 0x0
	.long	0x80008009, 0x0
	.long	0x8000000a, 0x0
	.long	0x8000808b, 0x0
	.long	0x8b, 0x80000000
	.long	0x8089, 0x80000000
	.long	0x8003, 0x80000000
	.long	0x8002, 0x80000000
	.long	0x80, 0x80000000
	.long	0x800a, 0x0
	.long	0x8000000a, 0x80000000
	.long	0x80008081, 0x80000000
	.long	0x8080, 0x80000000
	.long	0x80000001, 0x0
	.long	0x80008008, 0x80000000
	.type	keccakf_rndc, @object
	.size	keccakf_rndc, . - keccakf_rndc
	.section	.rodata
	.balign 4
	.globl	keccakf_rotc
keccakf_rotc:
	.long	1
	.long	3
	.long	6
	.long	10
	.long	15
	.long	21
	.long	28
	.long	36
	.long	45
	.long	55
	.long	2
	.long	14
	.long	27
	.long	41
	.long	56
	.long	8
	.long	25
	.long	43
	.long	62
	.long	18
	.long	39
	.long	61
	.long	20
	.long	44
	.type	keccakf_rotc, @object
	.size	keccakf_rotc, . - keccakf_rotc
	.section	.rodata
	.balign 4
	.globl	keccakf_piln
keccakf_piln:
	.long	10
	.long	7
	.long	11
	.long	17
	.long	18
	.long	3
	.long	5
	.long	16
	.long	8
	.long	21
	.long	24
	.long	4
	.long	15
	.long	23
	.long	19
	.long	13
	.long	12
	.long	2
	.long	20
	.long	14
	.long	22
	.long	9
	.long	6
	.long	1
	.type	keccakf_piln, @object
	.size	keccakf_piln, . - keccakf_piln
	.text
	.balign 2
	.globl keccakf
keccakf:
	addi	x30, x2, 0
	addi	x2, x2, -64
	sw	x30, 0(x2)
	sw	x1, 4(x2)
	sw	x8, 8(x2)
	sw	x9, 12(x2)
	sw	x18, 16(x2)
	addi	x29, x0, 0
	nop
	lw	x6, 0(x10)
	lw	x8, 4(x10)
	lw	x15, 40(x10)
	lw	x13, 44(x10)
	xor	x12, x8, x13
	xor	x11, x6, x15
	lw	x30, 80(x10)
	lw	x7, 84(x10)
	xor	x12, x12, x7
	xor	x16, x11, x30
	lw	x11, 120(x10)
	lw	x14, 124(x10)
	xor	x7, x12, x14
	xor	x12, x16, x11
	lw	x13, 160(x10)
	lw	x11, 164(x10)
	xor	x17, x7, x11
	xor	x14, x12, x13
	sw	x14, 24(x2)
	sw	x17, 28(x2)
	lw	x15, 8(x10)
	lw	x5, 12(x10)
	lw	x13, 48(x10)
	lw	x30, 52(x10)
	xor	x11, x5, x30
	xor	x15, x15, x13
	lw	x12, 88(x10)
	lw	x16, 92(x10)
	xor	x30, x11, x16
	xor	x15, x15, x12
	lw	x28, 128(x10)
	lw	x11, 132(x10)
	xor	x16, x30, x11
	xor	x7, x15, x28
	lw	x12, 168(x10)
	lw	x5, 172(x10)
	xor	x11, x16, x5
	xor	x7, x7, x12
	sw	x7, 32(x2)
	sw	x11, 36(x2)
	lw	x28, 16(x10)
	lw	x12, 20(x10)
	lw	x5, 56(x10)
	lw	x30, 60(x10)
	xor	x30, x12, x30
	xor	x12, x28, x5
	lw	x13, 96(x10)
	lw	x5, 100(x10)
	xor	x15, x30, x5
	xor	x28, x12, x13
	lw	x5, 136(x10)
	lw	x30, 140(x10)
	xor	x30, x15, x30
	xor	x15, x28, x5
	lw	x16, 176(x10)
	lw	x12, 180(x10)
	xor	x30, x30, x12
	xor	x12, x15, x16
	sw	x12, 40(x2)
	sw	x30, 44(x2)
	lw	x5, 24(x10)
	lw	x15, 28(x10)
	lw	x16, 64(x10)
	lw	x13, 68(x10)
	xor	x15, x15, x13
	xor	x5, x5, x16
	lw	x16, 104(x10)
	lw	x13, 108(x10)
	xor	x28, x15, x13
	xor	x13, x5, x16
	lw	x5, 144(x10)
	lw	x15, 148(x10)
	xor	x16, x28, x15
	xor	x15, x13, x5
	lw	x5, 184(x10)
	lw	x13, 188(x10)
	xor	x16, x16, x13
	xor	x28, x15, x5
	sw	x28, 48(x2)
	sw	x16, 52(x2)
	lw	x5, 32(x10)
	lw	x15, 36(x10)
	lw	x18, 72(x10)
	lw	x13, 76(x10)
	xor	x9, x15, x13
	xor	x15, x5, x18
	lw	x18, 112(x10)
	lw	x13, 116(x10)
	xor	x5, x9, x13
	xor	x15, x15, x18
	lw	x9, 152(x10)
	lw	x13, 156(x10)
	xor	x13, x5, x13
	xor	x15, x15, x9
	lw	x9, 192(x10)
	lw	x5, 196(x10)
	xor	x13, x13, x5
	xor	x15, x15, x9
	sw	x15, 56(x2)
	sw	x13, 60(x2)
	slli	x9, x11, 1
	srli	x5, x7, 31
	or	x9, x9, x5
	slli	x5, x7, 1
	srli	x18, x11, 31
	or	x5, x5, x18
	xor	x18, x13, x9
	xor	x9, x15, x5
	xor	x8, x8, x18
	xor	x5, x6, x9
	sw	x5, 0(x10)
	sw	x8, 4(x10)
	lw	x5, 40(x10)
	lw	x6, 44(x10)
	xor	x6, x6, x18
	xor	x5, x5, x9
	sw	x5, 40(x10)
	sw	x6, 44(x10)
	lw	x5, 80(x10)
	lw	x6, 84(x10)
	xor	x6, x6, x18
	xor	x5, x5, x9
	sw	x5, 80(x10)
	sw	x6, 84(x10)
	lw	x5, 120(x10)
	lw	x6, 124(x10)
	xor	x6, x6, x18
	xor	x5, x5, x9
	sw	x5, 120(x10)
	sw	x6, 124(x10)
	lw	x5, 160(x10)
	lw	x6, 164(x10)
	xor	x6, x6, x18
	xor	x5, x5, x9
	sw	x5, 160(x10)
	sw	x6, 164(x10)
	slli	x6, x30, 1
	srli	x5, x12, 31
	or	x6, x6, x5
	slli	x5, x12, 1
	srli	x8, x30, 31
	or	x5, x5, x8
	xor	x6, x17, x6
	xor	x5, x14, x5
	lw	x8, 8(x10)
	lw	x9, 12(x10)
	xor	x9, x9, x6
	xor	x8, x8, x5
	sw	x8, 8(x10)
	sw	x9, 12(x10)
	lw	x8, 48(x10)
	lw	x9, 52(x10)
	xor	x9, x9, x6
	xor	x8, x8, x5
	sw	x8, 48(x10)
	sw	x9, 52(x10)
	lw	x8, 88(x10)
	lw	x9, 92(x10)
	xor	x9, x9, x6
	xor	x8, x8, x5
	sw	x8, 88(x10)
	sw	x9, 92(x10)
	lw	x8, 128(x10)
	lw	x9, 132(x10)
	xor	x9, x9, x6
	xor	x8, x8, x5
	sw	x8, 128(x10)
	sw	x9, 132(x10)
	lw	x8, 168(x10)
	lw	x9, 172(x10)
	xor	x6, x9, x6
	xor	x5, x8, x5
	sw	x5, 168(x10)
	sw	x6, 172(x10)
	slli	x5, x16, 1
	srli	x6, x28, 31
	or	x8, x5, x6
	slli	x6, x28, 1
	srli	x5, x16, 31
	or	x5, x6, x5
	xor	x6, x11, x8
	xor	x7, x7, x5
	lw	x5, 16(x10)
	lw	x11, 20(x10)
	xor	x8, x11, x6
	xor	x11, x5, x7
	sw	x11, 16(x10)
	sw	x8, 20(x10)
	lw	x5, 56(x10)
	lw	x11, 60(x10)
	xor	x8, x11, x6
	xor	x11, x5, x7
	sw	x11, 56(x10)
	sw	x8, 60(x10)
	lw	x5, 96(x10)
	lw	x11, 100(x10)
	xor	x11, x11, x6
	xor	x5, x5, x7
	sw	x5, 96(x10)
	sw	x11, 100(x10)
	lw	x5, 136(x10)
	lw	x11, 140(x10)
	xor	x11, x11, x6
	xor	x5, x5, x7
	sw	x5, 136(x10)
	sw	x11, 140(x10)
	lw	x5, 176(x10)
	lw	x11, 180(x10)
	xor	x6, x11, x6
	xor	x5, x5, x7
	sw	x5, 176(x10)
	sw	x6, 180(x10)
	slli	x5, x13, 1
	srli	x6, x15, 31
	or	x11, x5, x6
	slli	x15, x15, 1
	srli	x5, x13, 31
	or	x13, x15, x5
	xor	x15, x30, x11
	xor	x5, x12, x13
	lw	x30, 24(x10)
	lw	x6, 28(x10)
	xor	x12, x6, x15
	xor	x11, x30, x5
	sw	x11, 24(x10)
	sw	x12, 28(x10)
	lw	x30, 64(x10)
	lw	x13, 68(x10)
	xor	x6, x13, x15
	xor	x30, x30, x5
	sw	x30, 64(x10)
	sw	x6, 68(x10)
	lw	x13, 104(x10)
	lw	x30, 108(x10)
	xor	x6, x30, x15
	xor	x30, x13, x5
	sw	x30, 104(x10)
	sw	x6, 108(x10)
	lw	x30, 144(x10)
	lw	x6, 148(x10)
	xor	x7, x6, x15
	xor	x6, x30, x5
	sw	x6, 144(x10)
	sw	x7, 148(x10)
	lw	x30, 184(x10)
	lw	x6, 188(x10)
	xor	x6, x6, x15
	xor	x15, x30, x5
	sw	x15, 184(x10)
	sw	x6, 188(x10)
	slli	x11, x17, 1
	srli	x30, x14, 31
	or	x5, x11, x30
	slli	x30, x14, 1
	srli	x6, x17, 31
	or	x12, x30, x6
	xor	x11, x16, x5
	xor	x28, x28, x12
	lw	x12, 32(x10)
	lw	x13, 36(x10)
	xor	x13, x13, x11
	xor	x12, x12, x28
	sw	x12, 32(x10)
	sw	x13, 36(x10)
	lw	x7, 72(x10)
	lw	x16, 76(x10)
	xor	x13, x16, x11
	xor	x12, x7, x28
	sw	x12, 72(x10)
	sw	x13, 76(x10)
	lw	x14, 112(x10)
	lw	x30, 116(x10)
	xor	x17, x30, x11
	xor	x16, x14, x28
	sw	x16, 112(x10)
	sw	x17, 116(x10)
	lw	x12, 152(x10)
	lw	x13, 156(x10)
	xor	x17, x13, x11
	xor	x16, x12, x28
	sw	x16, 152(x10)
	sw	x17, 156(x10)
	lw	x12, 192(x10)
	lw	x13, 196(x10)
	xor	x11, x13, x11
	xor	x7, x12, x28
	sw	x7, 192(x10)
	sw	x11, 196(x10)
	lw	x16, 8(x10)
	lw	x17, 12(x10)
	lw	x11, 80(x10)
	lw	x30, 84(x10)
	sw	x11, 24(x2)
	sw	x30, 28(x2)
	slli	x15, x17, 1
	srli	x5, x16, 31
	or	x28, x15, x5
	slli	x15, x16, 1
	srli	x12, x17, 31
	or	x5, x15, x12
	sw	x5, 80(x10)
	sw	x28, 84(x10)
	lw	x5, 56(x10)
	lw	x13, 60(x10)
	sw	x5, 24(x2)
	sw	x13, 28(x2)
	slli	x6, x30, 3
	srli	x7, x11, 29
	or	x14, x6, x7
	slli	x11, x11, 3
	srli	x16, x30, 29
	or	x30, x11, x16
	sw	x30, 56(x10)
	sw	x14, 60(x10)
	lw	x11, 88(x10)
	lw	x7, 92(x10)
	sw	x11, 24(x2)
	sw	x7, 28(x2)
	slli	x16, x13, 6
	srli	x6, x5, 26
	or	x6, x16, x6
	slli	x5, x5, 6
	srli	x12, x13, 26
	or	x17, x5, x12
	sw	x17, 88(x10)
	sw	x6, 92(x10)
	lw	x17, 136(x10)
	lw	x13, 140(x10)
	sw	x17, 24(x2)
	sw	x13, 28(x2)
	slli	x14, x7, 10
	srli	x12, x11, 22
	or	x6, x14, x12
	slli	x28, x11, 10
	srli	x15, x7, 22
	or	x12, x28, x15
	sw	x12, 136(x10)
	sw	x6, 140(x10)
	lw	x28, 144(x10)
	lw	x12, 148(x10)
	sw	x28, 24(x2)
	sw	x12, 28(x2)
	slli	x5, x13, 15
	srli	x14, x17, 17
	or	x6, x5, x14
	slli	x30, x17, 15
	srli	x13, x13, 17
	or	x11, x30, x13
	sw	x11, 144(x10)
	sw	x6, 148(x10)
	lw	x13, 24(x10)
	lw	x30, 28(x10)
	sw	x13, 24(x2)
	sw	x30, 28(x2)
	slli	x15, x12, 21
	srli	x7, x28, 11
	or	x17, x15, x7
	slli	x14, x28, 21
	srli	x16, x12, 11
	or	x6, x14, x16
	sw	x6, 24(x10)
	sw	x17, 28(x10)
	lw	x5, 40(x10)
	lw	x6, 44(x10)
	sw	x5, 24(x2)
	sw	x6, 28(x2)
	slli	x7, x30, 28
	srli	x28, x13, 4
	or	x7, x7, x28
	slli	x16, x13, 28
	srli	x30, x30, 4
	or	x12, x16, x30
	sw	x12, 40(x10)
	sw	x7, 44(x10)
	lw	x7, 128(x10)
	lw	x30, 132(x10)
	sw	x7, 24(x2)
	sw	x30, 28(x2)
	srli	x17, x6, 28
	srli	x16, x5, 28
	slli	x12, x6, 4
	or	x15, x16, x12
	slli	x11, x5, 4
	or	x16, x11, x17
	sw	x15, 128(x10)
	sw	x16, 132(x10)
	lw	x16, 64(x10)
	lw	x5, 68(x10)
	sw	x16, 24(x2)
	sw	x5, 28(x2)
	srli	x6, x30, 19
	srli	x11, x7, 19
	slli	x12, x30, 13
	or	x28, x11, x12
	slli	x14, x7, 13
	or	x11, x14, x6
	sw	x28, 64(x10)
	sw	x11, 68(x10)
	lw	x13, 168(x10)
	lw	x30, 172(x10)
	sw	x13, 24(x2)
	sw	x30, 28(x2)
	srli	x15, x5, 9
	srli	x14, x16, 9
	slli	x11, x5, 23
	or	x14, x14, x11
	slli	x5, x16, 23
	or	x11, x5, x15
	sw	x14, 168(x10)
	sw	x11, 172(x10)
	lw	x17, 192(x10)
	lw	x15, 196(x10)
	sw	x17, 24(x2)
	sw	x15, 28(x2)
	slli	x14, x30, 2
	srli	x16, x13, 30
	or	x14, x14, x16
	slli	x11, x13, 2
	srli	x6, x30, 30
	or	x5, x11, x6
	sw	x5, 192(x10)
	sw	x14, 196(x10)
	lw	x5, 32(x10)
	lw	x6, 36(x10)
	sw	x5, 24(x2)
	sw	x6, 28(x2)
	slli	x11, x15, 14
	srli	x12, x17, 18
	or	x11, x11, x12
	slli	x7, x17, 14
	srli	x30, x15, 18
	or	x15, x7, x30
	sw	x15, 32(x10)
	sw	x11, 36(x10)
	lw	x14, 120(x10)
	lw	x15, 124(x10)
	sw	x14, 24(x2)
	sw	x15, 28(x2)
	slli	x7, x6, 27
	srli	x13, x5, 5
	or	x30, x7, x13
	slli	x28, x5, 27
	srli	x17, x6, 5
	or	x7, x28, x17
	sw	x7, 120(x10)
	sw	x30, 124(x10)
	lw	x12, 184(x10)
	lw	x13, 188(x10)
	sw	x12, 24(x2)
	sw	x13, 28(x2)
	srli	x11, x15, 23
	srli	x5, x14, 23
	slli	x30, x15, 9
	or	x5, x5, x30
	slli	x14, x14, 9
	or	x6, x14, x11
	sw	x5, 184(x10)
	sw	x6, 188(x10)
	lw	x15, 152(x10)
	lw	x11, 156(x10)
	sw	x15, 24(x2)
	sw	x11, 28(x2)
	srli	x17, x13, 8
	srli	x28, x12, 8
	slli	x13, x13, 24
	or	x7, x28, x13
	slli	x30, x12, 24
	or	x12, x30, x17
	sw	x7, 152(x10)
	sw	x12, 156(x10)
	lw	x13, 104(x10)
	lw	x14, 108(x10)
	sw	x13, 24(x2)
	sw	x14, 28(x2)
	slli	x6, x11, 8
	srli	x5, x15, 24
	or	x16, x6, x5
	slli	x12, x15, 8
	srli	x17, x11, 24
	or	x5, x12, x17
	sw	x5, 104(x10)
	sw	x16, 108(x10)
	lw	x6, 96(x10)
	lw	x12, 100(x10)
	sw	x6, 24(x2)
	sw	x12, 28(x2)
	slli	x15, x14, 25
	srli	x16, x13, 7
	or	x15, x15, x16
	slli	x16, x13, 25
	srli	x17, x14, 7
	or	x17, x16, x17
	sw	x17, 96(x10)
	sw	x15, 100(x10)
	lw	x5, 16(x10)
	lw	x16, 20(x10)
	sw	x5, 24(x2)
	sw	x16, 28(x2)
	srli	x28, x12, 21
	srli	x7, x6, 21
	slli	x30, x12, 11
	or	x17, x7, x30
	slli	x11, x6, 11
	or	x28, x11, x28
	sw	x17, 16(x10)
	sw	x28, 20(x10)
	lw	x7, 160(x10)
	lw	x30, 164(x10)
	sw	x7, 24(x2)
	sw	x30, 28(x2)
	srli	x11, x16, 2
	srli	x17, x5, 2
	slli	x14, x16, 30
	or	x13, x17, x14
	slli	x12, x5, 30
	or	x15, x12, x11
	sw	x13, 160(x10)
	sw	x15, 164(x10)
	lw	x16, 112(x10)
	lw	x14, 116(x10)
	sw	x16, 24(x2)
	sw	x14, 28(x2)
	slli	x5, x30, 18
	srli	x15, x7, 14
	or	x5, x5, x15
	slli	x15, x7, 18
	srli	x17, x30, 14
	or	x11, x15, x17
	sw	x11, 112(x10)
	sw	x5, 116(x10)
	lw	x30, 176(x10)
	lw	x17, 180(x10)
	sw	x30, 24(x2)
	sw	x17, 28(x2)
	srli	x11, x14, 25
	srli	x12, x16, 25
	slli	x13, x14, 7
	or	x12, x12, x13
	slli	x28, x16, 7
	or	x11, x28, x11
	sw	x12, 176(x10)
	sw	x11, 180(x10)
	lw	x13, 72(x10)
	lw	x6, 76(x10)
	sw	x13, 24(x2)
	sw	x6, 28(x2)
	srli	x14, x17, 3
	srli	x15, x30, 3
	slli	x7, x17, 29
	or	x7, x15, x7
	slli	x16, x30, 29
	or	x11, x16, x14
	sw	x7, 72(x10)
	sw	x11, 76(x10)
	lw	x5, 48(x10)
	lw	x7, 52(x10)
	sw	x5, 24(x2)
	sw	x7, 28(x2)
	slli	x11, x6, 20
	srli	x12, x13, 12
	or	x30, x11, x12
	slli	x17, x13, 20
	srli	x6, x6, 12
	or	x13, x17, x6
	sw	x13, 48(x10)
	sw	x30, 52(x10)
	lw	x13, 8(x10)
	lw	x30, 12(x10)
	sw	x13, 24(x2)
	sw	x30, 28(x2)
	srli	x30, x7, 20
	srli	x11, x5, 20
	slli	x16, x7, 12
	or	x17, x11, x16
	slli	x11, x5, 12
	or	x28, x11, x30
	sw	x17, 8(x10)
	sw	x28, 12(x10)
	addi	x28, x0, 0
	nop
	slli	x6, x28, 3
	add	x30, x10, x6
	lw	x14, 0(x30)
	lw	x5, 4(x30)
	sw	x14, 24(x2)
	sw	x5, 28(x2)
	lw	x5, 8(x30)
	lw	x6, 12(x30)
	sw	x5, 32(x2)
	sw	x6, 36(x2)
	lw	x7, 16(x30)
	lw	x16, 20(x30)
	sw	x7, 40(x2)
	sw	x16, 44(x2)
	lw	x11, 24(x30)
	lw	x14, 28(x30)
	sw	x11, 48(x2)
	sw	x14, 52(x2)
	lw	x11, 32(x30)
	lw	x12, 36(x30)
	sw	x11, 56(x2)
	sw	x12, 60(x2)
	lw	x13, 0(x30)
	lw	x12, 4(x30)
	xori	x14, x6, -1
	xori	x5, x5, -1
	and	x6, x14, x16
	and	x15, x5, x7
	xor	x12, x12, x6
	xor	x11, x13, x15
	sw	x11, 0(x30)
	sw	x12, 4(x30)
	lw	x5, 8(x30)
	lw	x14, 12(x30)
	lw	x13, 40(x2)
	lw	x11, 44(x2)
	xori	x11, x11, -1
	xori	x7, x13, -1
	lw	x12, 48(x2)
	lw	x6, 52(x2)
	and	x16, x11, x6
	and	x15, x7, x12
	xor	x13, x14, x16
	xor	x12, x5, x15
	sw	x12, 8(x30)
	sw	x13, 12(x30)
	lw	x15, 16(x30)
	lw	x12, 20(x30)
	lw	x11, 48(x2)
	lw	x13, 52(x2)
	xori	x16, x13, -1
	xori	x11, x11, -1
	lw	x14, 56(x2)
	lw	x7, 60(x2)
	and	x13, x16, x7
	and	x5, x11, x14
	xor	x12, x12, x13
	xor	x11, x15, x5
	sw	x11, 16(x30)
	sw	x12, 20(x30)
	lw	x15, 24(x30)
	lw	x11, 28(x30)
	lw	x14, 56(x2)
	lw	x16, 60(x2)
	xori	x5, x16, -1
	xori	x6, x14, -1
	lw	x7, 24(x2)
	lw	x13, 28(x2)
	and	x16, x5, x13
	and	x12, x6, x7
	xor	x6, x11, x16
	xor	x5, x15, x12
	sw	x5, 24(x30)
	sw	x6, 28(x30)
	lw	x12, 32(x30)
	lw	x5, 36(x30)
	lw	x11, 24(x2)
	lw	x6, 28(x2)
	xori	x6, x6, -1
	xori	x14, x11, -1
	lw	x11, 32(x2)
	lw	x17, 36(x2)
	and	x6, x6, x17
	and	x7, x14, x11
	xor	x6, x5, x6
	xor	x5, x12, x7
	sw	x5, 32(x30)
	sw	x6, 36(x30)
	addi	x28, x28, 5
	addi	x31, x0, 25
    blt  x28, x31, -182
	lw	x12, 0(x10)
	lw	x28, 4(x10)
    lui	x17, %lo(keccakf_rndc)
    addi  x17, x17, %lo(keccakf_rndc)
	slli	x30, x29, 3
	add	x17, x17, x30
	lw	x5, 0(x17)
	lw	x30, 4(x17)
	xor	x14, x28, x30
	xor	x13, x12, x5
	sw	x13, 0(x10)
	sw	x14, 4(x10)
	addi	x29, x29, 1
	addi	x31, x0, 24
    blt  x29, x31, -1372
	lw	x8, 8(x2)
	lw	x9, 12(x2)
	lw	x18, 16(x2)
	lw	x1, 4(x2)
	addi	x2, x2, 64
    jalr   x0, x1, 0
	.type	keccakf, @function
	.size	keccakf, . - keccakf
	.text
	.balign 2
	.globl keccak
keccak:
	addi	x30, x2, 0
	addi	x2, x2, -384
	sw	x30, 0(x2)
	sw	x1, 4(x2)
	sw	x8, 8(x2)
	sw	x9, 12(x2)
	sw	x18, 16(x2)
	sw	x19, 20(x2)
	sw	x20, 24(x2)
	sw	x21, 28(x2)
	addi	x8, x13, 0
	addi	x9, x12, 0
	addi	x21, x11, 0
	addi	x20, x10, 0
	addi	x5, x0, 200
	slli	x29, x8, 1
	sub	x19, x5, x29
	srai	x31, x19, 31
	srli	x31, x31, 29
	add	x31, x19, x31
	srai	x18, x31, 3
	addi	x10, x2, 176
	addi	x11, x0, 0
	addi	x12, x0, 200
    jal   x1, memset
	nop
    blt  x21, x19, 84
	addi	x5, x0, 0
	nop
    bge  x5, x18, 66
	slli	x12, x5, 3
	add	x6, x20, x12
	lbu	x16, 0(x6)
	lbu	x29, 1(x6)
	slli	x10, x29, 8
	or	x15, x16, x10
	lbu	x11, 2(x6)
	slli	x13, x11, 16
	or	x16, x15, x13
	lbu	x14, 3(x6)
	slli	x14, x14, 24
	or	x15, x16, x14
	lbu	x13, 4(x6)
	lbu	x14, 5(x6)
	slli	x28, x14, 8
	or	x13, x13, x28
	lbu	x17, 6(x6)
	slli	x28, x17, 16
	or	x16, x13, x28
	lbu	x17, 7(x6)
	slli	x6, x17, 24
	or	x11, x16, x6
	addi	x6, x2, 176
	add	x29, x6, x12
	lw	x17, 0(x29)
	lw	x12, 4(x29)
	xor	x13, x12, x11
	xor	x12, x17, x15
	sw	x12, 0(x29)
	sw	x13, 4(x29)
	addi	x5, x5, 1
    jal   x0, -66
	nop
	addi	x10, x2, 176
    jal   x1, keccakf
	sub	x21, x21, x19
	add	x20, x20, x19
    jal   x0, -84
	nop
	addi	x10, x2, 32
	addi	x12, x21, 0
	addi	x11, x20, 0
    jal   x1, memcpy
	addi	x12, x21, 1
	addi	x29, x2, 32
	add	x11, x29, x21
	addi	x7, x0, 1
	sb	x7, 0(x11)
	addi	x7, x2, 32
	add	x10, x7, x12
	addi	x11, x0, 0
	sub	x12, x19, x12
    jal   x1, memset
	addi	x6, x2, 31
	add	x30, x6, x19
	lbu	x17, 0(x30)
	ori	x13, x17, 128
	sb	x13, 0(x30)
	addi	x7, x0, 0
	nop
    bge  x7, x18, 68
	addi	x15, x2, 32
	slli	x16, x7, 3
	add	x15, x15, x16
	lbu	x13, 0(x15)
	lbu	x30, 1(x15)
	slli	x28, x30, 8
	or	x17, x13, x28
	lbu	x10, 2(x15)
	slli	x29, x10, 16
	or	x13, x17, x29
	lbu	x10, 3(x15)
	slli	x12, x10, 24
	or	x29, x13, x12
	lbu	x6, 4(x15)
	lbu	x17, 5(x15)
	slli	x17, x17, 8
	or	x10, x6, x17
	lbu	x28, 6(x15)
	slli	x30, x28, 16
	or	x12, x10, x30
	lbu	x13, 7(x15)
	slli	x5, x13, 24
	or	x30, x12, x5
	addi	x6, x2, 176
	add	x5, x6, x16
	lw	x10, 0(x5)
	lw	x14, 4(x5)
	xor	x28, x14, x30
	xor	x17, x10, x29
	sw	x17, 0(x5)
	sw	x28, 4(x5)
	addi	x7, x7, 1
    jal   x0, -68
	nop
	addi	x10, x2, 176
    jal   x1, keccakf
	addi	x12, x0, 0
	nop
	addi	x14, x2, 32
	slli	x10, x12, 3
	add	x13, x14, x10
	addi	x14, x2, 176
	add	x10, x14, x10
	lw	x11, 0(x10)
	lw	x5, 4(x10)
	sb	x11, 0(x13)
	srli	x6, x5, 8
	srli	x30, x11, 8
	slli	x17, x5, 24
	or	x7, x30, x17
	sb	x7, 1(x13)
	srli	x16, x5, 16
	srli	x15, x11, 16
	slli	x30, x5, 16
	or	x14, x15, x30
	sb	x14, 2(x13)
	srli	x10, x5, 24
	srli	x7, x11, 24
	slli	x14, x5, 8
	or	x11, x7, x14
	sb	x11, 3(x13)
	sb	x5, 4(x13)
	sb	x6, 5(x13)
	sb	x16, 6(x13)
	sb	x10, 7(x13)
	addi	x12, x12, 1
	addi	x31, x0, 8
    blt  x12, x31, -60
	addi	x11, x2, 32
	addi	x12, x8, 0
	addi	x10, x9, 0
    jal   x1, memcpy
	lw	x8, 8(x2)
	lw	x9, 12(x2)
	lw	x18, 16(x2)
	lw	x19, 20(x2)
	lw	x20, 24(x2)
	lw	x21, 28(x2)
	lw	x1, 4(x2)
	addi	x2, x2, 384
    jalr   x0, x1, 0
	.type	keccak, @function
	.size	keccak, . - keccak
	.data
	.balign 4
	.globl	testvec
testvec:
	.long	28
	.long	__stringlit_4
	.byte	48
	.byte	4
	.byte	91
	.byte	52
	.byte	148
	.byte	110
	.byte	27
	.byte	46
	.byte	9
	.byte	22
	.byte	19
	.byte	54
	.byte	47
	.byte	210
	.byte	42
	.byte	160
	.byte	142
	.byte	43
	.byte	234
	.byte	254
	.byte	197
	.byte	232
	.byte	218
	.byte	238
	.byte	66
	.byte	194
	.byte	230
	.byte	101
	.space	36
	.long	32
	.long	__stringlit_3
	.byte	168
	.byte	215
	.byte	27
	.byte	7
	.byte	244
	.byte	175
	.byte	38
	.byte	164
	.byte	255
	.byte	33
	.byte	2
	.byte	127
	.byte	98
	.byte	255
	.byte	96
	.byte	38
	.byte	127
	.byte	249
	.byte	85
	.byte	201
	.byte	99
	.byte	240
	.byte	66
	.byte	196
	.byte	109
	.byte	165
	.byte	46
	.byte	227
	.byte	207
	.byte	175
	.byte	61
	.byte	60
	.space	32
	.long	48
	.long	__stringlit_2
	.byte	226
	.byte	19
	.byte	253
	.byte	116
	.byte	175
	.byte	12
	.byte	95
	.byte	249
	.byte	27
	.byte	66
	.byte	60
	.byte	139
	.byte	206
	.byte	236
	.byte	215
	.byte	1
	.byte	248
	.byte	221
	.byte	100
	.byte	236
	.byte	24
	.byte	253
	.byte	111
	.byte	146
	.byte	96
	.byte	252
	.byte	158
	.byte	193
	.byte	237
	.byte	189
	.byte	34
	.byte	48
	.byte	166
	.byte	144
	.byte	134
	.byte	101
	.byte	188
	.byte	217
	.byte	251
	.byte	244
	.byte	26
	.byte	153
	.byte	161
	.byte	138
	.byte	125
	.byte	158
	.byte	68
	.byte	110
	.space	16
	.long	64
	.long	__stringlit_1
	.byte	150
	.byte	238
	.byte	71
	.byte	24
	.byte	220
	.byte	186
	.byte	60
	.byte	116
	.byte	97
	.byte	155
	.byte	161
	.byte	250
	.byte	127
	.byte	87
	.byte	223
	.byte	231
	.byte	118
	.byte	157
	.byte	63
	.byte	102
	.byte	152
	.byte	168
	.byte	179
	.byte	63
	.byte	161
	.byte	1
	.byte	131
	.byte	137
	.byte	112
	.byte	161
	.byte	49
	.byte	230
	.byte	33
	.byte	204
	.byte	253
	.byte	5
	.byte	254
	.byte	255
	.byte	188
	.byte	17
	.byte	128
	.byte	242
	.byte	99
	.byte	194
	.byte	127
	.byte	26
	.byte	218
	.byte	180
	.byte	96
	.byte	149
	.byte	214
	.byte	241
	.byte	37
	.byte	51
	.byte	20
	.byte	114
	.byte	75
	.byte	92
	.byte	191
	.byte	120
	.byte	40
	.byte	101
	.byte	142
	.byte	106
	.type	testvec, @object
	.size	testvec, . - testvec
	.local	data
	.comm	data, 100000, 1
	.text
	.balign 2
	.globl main
main:
	addi	x30, x2, 0
	addi	x2, x2, -80
	sw	x30, 0(x2)
	sw	x1, 4(x2)
	sw	x8, 8(x2)
	addi	x8, x0, 0
	nop
    lui	x6, %lo(testvec)
    addi  x6, x6, %lo(testvec)
	slli	x14, x8, 3
	slli	x15, x8, 6
	add	x10, x14, x15
	add	x29, x6, x10
	lw	x10, 4(x29)
    jal   x1, strlen
	addi	x11, x10, 0
    lui	x12, %lo(testvec)
    addi  x12, x12, %lo(testvec)
	slli	x16, x8, 3
	slli	x30, x8, 6
	add	x13, x16, x30
	add	x7, x12, x13
	lw	x10, 4(x7)
	addi	x12, x2, 16
	lw	x13, 0(x7)
    jal   x1, keccak
	addi	x10, x2, 16
    lui	x12, %lo(testvec)
    addi  x12, x12, %lo(testvec)
	slli	x11, x8, 3
	slli	x28, x8, 6
	add	x7, x11, x28
	add	x6, x12, x7
	addi	x11, x6, 8
	lw	x12, 0(x6)
    jal   x1, memcmp
    beq  x10, x0, 8
    lui	x12, %lo(__stringlit_5)
    addi  x12, x12, %lo(__stringlit_5)
    jal   x0, 8
	nop
    lui	x12, %lo(__stringlit_6)
    addi  x12, x12, %lo(__stringlit_6)
	nop
    lui	x10, %lo(__stringlit_7)
    addi  x10, x10, %lo(__stringlit_7)
    lui	x11, %lo(testvec)
    addi  x11, x11, %lo(testvec)
	slli	x15, x8, 3
	slli	x30, x8, 6
	add	x13, x15, x30
	add	x16, x11, x13
	lw	x11, 0(x16)
	slli	x11, x11, 3
    jal   x1, printf
	addi	x8, x8, 1
	addi	x31, x0, 4
    blt  x8, x31, -102
	addi	x5, x0, 0
	nop
    lui	x17, %lo(data)
    addi  x17, x17, %lo(data)
	add	x28, x17, x5
	sb	x5, 0(x28)
	addi	x5, x5, 1
	lui	x31, 24
	addi	x31, x31, 1696
    blt  x5, x31, -16
	addi	x8, x0, 0
	nop
    lui	x10, %lo(data)
    addi  x10, x10, %lo(data)
	lui	x11, 24
	addi	x11, x11, 1696
	addi	x12, x2, 16
	addi	x13, x0, 64
    jal   x1, keccak
	addi	x8, x8, 1
	addi	x31, x0, 25
    blt  x8, x31, -20
	addi	x10, x0, 0
	lw	x8, 8(x2)
	lw	x1, 4(x2)
	addi	x2, x2, 80
    jalr   x0, x1, 0
	.type	main, @function
	.size	main, . - main
